import csv
from pathlib import Path

OUTPUT_FILE = Path("thread_protocol_index.csv")


def find_thread_files():
    """Return all markdown or CSV files containing "THREAD" in their name.

    The search spans the entire repository to be exhaustive. The output CSV
    generated by this script is excluded to prevent self-referencing.
    """
    patterns = ["*THREAD*.md", "*THREAD*.csv"]
    files = set()
    for pattern in patterns:
        files.update(Path('.').rglob(pattern))
    # Avoid including the output file itself
    return sorted(p for p in files if p.resolve() != OUTPUT_FILE.resolve())

def parse_markdown_table(file_path):
    """Parse markdown table rows for thread entries.

    Expects rows formatted like:
    | THxxx | Title | timestamp | ... |
    Returns list of dicts with thread_id, title, timestamp.
    """
    rows = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if line.startswith('| TH'):
                # remove leading/trailing '|'
                parts = [p.strip() for p in line.strip('|').split('|')]
                if len(parts) >= 3:
                    rows.append(
                        {
                            "thread_id": parts[0],
                            "title": parts[1],
                            "timestamp": parts[2],
                            "source_file": str(file_path),
                        }
                    )
    return rows


def parse_csv_table(file_path):
    """Parse CSV files for thread entries."""
    rows = []
    with open(file_path, newline="", encoding="utf-8") as f:
        reader = csv.reader(f)
        headers = next(reader, None)
        for row in reader:
            if row and row[0].startswith("TH"):
                title = row[1] if len(row) > 1 else ""
                timestamp = row[2] if len(row) > 2 else ""
                rows.append(
                    {
                        "thread_id": row[0],
                        "title": title,
                        "timestamp": timestamp,
                        "source_file": str(file_path),
                    }
                )
    return rows

def build_index():
    rows = []
    for file_path in find_thread_files():
        if file_path.suffix.lower() == ".md":
            rows.extend(parse_markdown_table(file_path))
        elif file_path.suffix.lower() == ".csv":
            rows.extend(parse_csv_table(file_path))

    rows.sort(key=lambda r: (r["thread_id"], r["source_file"]))

    with open(OUTPUT_FILE, "w", newline="", encoding="utf-8") as csvfile:
        fieldnames = ["thread_id", "title", "timestamp", "source_file"]
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(rows)

def main():
    build_index()
    print(f"Wrote {OUTPUT_FILE}")

if __name__ == '__main__':
    main()
